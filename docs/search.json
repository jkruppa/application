[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Spielwiese Bio Data Science",
    "section": "",
    "text": "Willkommen\n\nEr ist tot, Jim — Dieses Buch ist tot und die Idee, die ich mit dem Buch hatte, funktioniert nicht. Daher ist hier Schluß. Besuche gerne das Hauptbuch der Bio Data Sciene, aber hier wird jetzt nichts mehr passieren. Danke für die Aufmerksamkeit.\n\nAlle Beispiele sind aus meiner beratenden Tätigkeit hier an der Hochschule Osnabrück entstanden. Keins der Beispiele ist so echt. Ich habe die Daten geändert und Behandlungen entfernt oder dazu genommen. Teilweise habe ich mir die Geschichte um die Fragestellung auch einfach ausgedacht. Also die Beispiel sind dann biologisch inhaltlich vielleicht dann doch eher Unsinn, die statistische Methode darum sollte aber meistens korrekt sein."
  },
  {
    "objectID": "index.html#sec-contact-mail",
    "href": "index.html#sec-contact-mail",
    "title": "Spielwiese Bio Data Science",
    "section": "Kontakt",
    "text": "Kontakt\nWie erreichst du mich? Am einfachsten über die gute, alte E-Mail. Bitte beachte, dass gerade kurz vor den Prüfungen ich mehr E-Mails kriege. Leider kann es dann einen Tick dauern.\n\n\n\n\n\nEinfach an j.kruppa@hs-osnabrueck.de schreiben. Du findest hier auch eine kurze Formulierungshilfe. Einfach auf den Ausklapppfeil klicken.\n\n\n\n\n\n\nE-Mailvorlage mit beispielhafter Anrede\n\n\n\n\n\nHallo Herr Kruppa,\n… ich belege gerade Ihr Modul Modulname und hätte eine Bitte/Frage/Anregung…\n… ich benötige Hilfe bei der Planung/Auswertung meiner Bachelorarbeit…\nMit freundlichen Grüßen\nM. Muster"
  },
  {
    "objectID": "example-analysis-01.html",
    "href": "example-analysis-01.html",
    "title": "1  Wachstum nach Rückschnitt mit Messwiederholung",
    "section": "",
    "text": "Letzte Änderung am 13. January 2024 um 17:46:59\n\n\n\n\n\n\n\nGenutzte R Pakete\n\n\n\nWir wollen folgende R Pakete in diesem Kapitel nutzen.\n\npacman::p_load(tidyverse, magrittr, readxl, see, janitor,\n               psych, parameters, effectsize, emmeans,\n               multcomp, conflicted)\n## resolve some conflicts with same function naming\nconflict_prefer(\"select\", \"dplyr\")\nconflict_prefer(\"filter\", \"dplyr\")\n\n\n\nIn diesem Beispiel haben vier Outcomes mit shoot, flower, leaf und fruit gemessen. Wir nehmen hier an, dass wir es bei dem Outcome shoot mit einer Pflanzenhöhe zu tun haben und bei den drei anderen Outcomes jeweils mit einer Anzahl. Wir haben jeweils drei Pflanzen in zwei Blöcken randomisiert. Darüber hinaus haben wir vier Behandlungen. Einmal schauen wir uns eine Kontrolle an sowie drei Arten von Rückschnitten. Die Fragestellung ist nun, wie sich die Behandlung durch die Rückschnitte auf die Outcomes auswirkt.\nWir lesen wieder als erstes die Daten ein. Bitte beachte, dass wir den Versuch an acht Terminen ausgewertet haben. Das heißt, wir haben an acht Terminen alle vier Outcomes gemessen. Dadurch ergeben sich immer vier Spalten mit dem Namen des Outcomes ergänzt um eine Zahl für den Messtermin. Wir nutzen noch die Funktion clean_names() um sicherzugehen, dass wir keine Leerzeichen mehr in den Spaltennamen haben.\n\ncutting_raw_tbl &lt;- read_excel(\"data/cutting_data.xlsx\") %&gt;% \n  clean_names()\n\nNun müssen wir noch die Spalten shoot_1 bis zur letzten Spalte fruit_8 in drei Spalten verwandeln. In der einen Spalte rsp sollen nur die numerischen Messwerte stehen. In der Spalte week soll nur die Messwoche hinein und in die Spalte Outcome soll sich der Name der Spalte wiederfinden. Um diese Modifizierung der Daten zu erreichen, nutzen wir die Funktion pivot_longer(). Wir spalten die Namen der Spalten durch den Unterstrich _ in zwei neue Spalten outcome und week. Dann müssen wir noch die Daten sortieren und die Behandlung sowie die Blöcke in einen Faktor umwandeln. Damit wir später eine bessere Abbildung haben, verwandeln wir noch die Wochen in eine numerische Spalte.\n\ncutting_tbl &lt;- cutting_raw_tbl %&gt;% \n  pivot_longer(cols = shoot_1:fruit_8, \n               names_to = c(\"outcome\", \"week\"), \n               names_sep = \"_\",\n               values_to = \"rsp\") %&gt;% \n  arrange(outcome, week, trt, block, rsp) %&gt;% \n  mutate(block = as_factor(block),\n         trt = as_factor(trt),\n         outcome = as_factor(outcome),\n         week = as.numeric(week))\n\nJetzt wollen wir für die Abbildung 1.1 etwas andere Namen für unsere Outcomes. Dafür nutzen wir dann die Funktion recode() in der wir die Level eines Faktors umbenennen können. Nachdem wir das gemacht haben, stellen wir einmal die Verläufe der Outcomes über die Wochen getrennt für die Behandlungen und die Blöcke dar. Die Funktion stat_smooth() erlaubt uns einmal eine Gerade durch die Punkte zu legen.\n\ncutting_plot_tbl &lt;- cutting_tbl %&gt;% \n  mutate(outcome = recode(outcome, \n                          shoot = \"Trieblänge\", \n                          flower = \"Blütenanzahl\", \n                          leaf = \"Blätteranzahl\", \n                          fruit = \"Fruchtanzahl\"))\n\ncutting_plot_tbl %&gt;% \n  ggplot(aes(week, rsp, color = trt, linetype = block)) +\n  theme_minimal() +\n  facet_wrap(~ outcome, scales = \"free_y\") +\n  geom_point() +\n  stat_smooth(se = FALSE) +\n  scale_color_okabeito()\n\n\n\n\nAbbildung 1.1— Abbildung der vier Outcomes über die acht Messtermine mit den vier Behandlungen und den zwei Blöcken.\n\n\n\n\nWir wir erkennen können, sind die Blöcke ähnlich. Hier haben wir also gut randomisiert. Auch scheint keine gravierende Interaktion vorzuliegen. Die Abstände und der Anstieg ist über die Wochen relativ konstant. Wir werden uns am Ende auf die Woche acht konzentrieren, da wir an dem letzten Termin unsere multiplen Vergleiche rechnen wollen.\nHäufig ist es so, dass wir dann noch einen Barplot wollen. Hier ist aber Vorsicht geboten. Ein Barplot mit Mittelwert und Standardabweichung macht eigentlich nur Sinn, wenn das Outcome normalverteilt ist. Sonst können schnell negative oder ungewollte Werte raus kommen. Immerhin haben wir hier mit flower, leaf und fruit drei Outcomes die als Zähldaten einer Poissonverteilung folgen.\nUm die Mittelwerte für die Behandlungen getrennt für die Wochen zu berechnen, nutzen wir die Funktion group_by() um uns alle Paare von Behandlung und Woche zu bilden. Dann rechnen wir für jede dieser Paarungen dann den Mittelwert und die Standardabweichung aus. Wir mitteln aber hier über die Blöcke, um dann die Barplots überhaupt sinnvoll darstellen zu können.\n\nstat_tbl &lt;- cutting_plot_tbl %&gt;% \n  group_by(trt, outcome, week) %&gt;% \n  summarise(mean = mean(rsp),\n            sd = sd(rsp)) \n\nIn Abbildung 1.2 sehen wir die Barplots. Wir zu erwarten erhalten wir bei den Zäldaten negatuve Werte durch den Fehlerbalken angezeigt. Die Streuung ist hier zu groß und so sind die Fehlerbalken auch negativ. Barplots sind keine gute Lösung für die Darstellung von Zähldaten durch den Mittelwert und die Standardabweichung. Da wären dann Boxplots besser. Aber es ist immer gut mal was zu zeigen, was dann auch nicht so gut geht, also hier einmal die Barplots.\nAchtung, wenn du nicht normalverteilte Daten mit Barplots und den Fehlerbalken darstellst, dann kann es zu Fehlerbalken führen, die negativ werden\n\nggplot(stat_tbl, aes(x = week, y = mean, group = trt, fill = trt)) + \n  geom_bar(stat = \"identity\", position = position_dodge()) +\n  geom_errorbar(aes(ymin = mean-sd, ymax = mean+sd),\n                width = 0.2, position = position_dodge(0.9)) +\n  theme_bw() +\n  labs(fill = \"Behandlung\") +\n  facet_wrap(~ outcome, scales = \"free_y\") +\n  scale_fill_okabeito()\n\n\n\n\nAbbildung 1.2— Barplots mit Fehlerbalken der vier Outcomes über die acht Messtermine mit den vier Behandlungen und den zwei Blöcken.\n\n\n\n\nEine Frage, die sich im Rahmen der Analyse noch gestellt hat, war ob die Outcomes untereinander stark korrelieren. Daher wurde nochmal entschieden sich die Korrelation der vier Outcomes anzuschauen. Wir machen das jetzt erstmal über die Woche sechs bis Woche acht. In den früheren Wochen haben die Pflanzen noch keine Früchte und dann sehen die Abbildungen sehr seltsam verzerrt aus.\n\n\nEs gibt eine große Auswahl an R Paketen und damit auch Plots für die Korrelation. In dem Tutorial Correlation plot in R werden dir eine große Auwahl präsentiert.\nWir filtern uns also die Wochen sechs bis acht und nutzen dann die Funktion pivot_wider() um die Outcomes wieder nebeneinander in vier Spalten anzuordnen. Da pivot_wider() die wiederholenden Zeilen von Behandlung und Block zusammenfasst, müssen wir die Spalten nochmal wieder ausklappen. Dieses Ausklappen machen wir mit der Funktion unnest().\n\ncutting_cor_tbl &lt;- cutting_tbl %&gt;% \n  filter(week %in% c(6, 7, 8)) %&gt;% \n  pivot_wider(names_from = outcome, values_from = rsp) %&gt;% \n  unnest(cols = c(flower, fruit, leaf, shoot))\n\nIn Abbildung 1.3 sehen wir jetzt ein Beispiel für ein Korrelationsplot. Es gibt wirklich sehr viele Möglichkeiten in R sich die Korrelation von numerischen Spalten anzeigen zu lassen. Wir wählen hier nur den Korrelationskoeffizient nach Kendall, da wir hier nicht nur normalverteilte Outcomes vorliegen haben. In dem Histogramm auf der Diagonalen kannst du auch sehr gut die Poissonverteilungen von der Normalverteilung unterscheiden. Die Trieblänge ist normalverteilt und die anderen Outcomes mit den Anzahlen folgen einer Poissonverteilung.\n\ncutting_cor_tbl %&gt;% \n  select(flower:shoot) %&gt;% \n  pairs.panels(smooth = TRUE, density = TRUE, method = \"kendall\", lm = FALSE, \n               cor = TRUE, ellipses = FALSE, stars = TRUE)    \n\n\n\n\nAbbildung 1.3— Abbildung der Scatterplots, Histogramme und Korrelation zwischen den vier Outcomes.\n\n\n\n\nIm Folgenden wollen wir nochmal den Zusammenhang zwischen der Anzahl der Blätter über alle Termine und der Anzahl an Blüten über alle Termine darstellen. Dafür müssen wir einmal unsere Spalten nach leaf oder flower auswählen und dann zusammenklappen. Danach klappen wir dann die Spalte outcome wieder auseinander. Dann können wir uns die Abbildung erstellen.\n\ncutting_leaf_flower_tbl &lt;- cutting_raw_tbl %&gt;% \n  select(trt, block, matches(\"leaf|flower\")) %&gt;% \n  pivot_longer(cols = leaf_1:last_col(), \n               names_to = c(\"outcome\", \"week\"), \n               names_sep = \"_\",\n               values_to = \"rsp\") %&gt;% \n  pivot_wider(names_from = outcome,\n              values_from = rsp) %&gt;% \n  unnest(cols = c(flower, leaf))\n\nIn Abbildung 1.4 sehen wir dann den Zusammenhang zwischen der Anzahl der Blätter und der Anzahl an Blüten. Mit der Funktion stat_smooth() haben wir dann noch eine Gerade durch die Punkte gelegt.\n\ncutting_leaf_flower_tbl %&gt;% \n  ggplot(aes(leaf, flower, color = trt)) +\n  theme_minimal() +\n  geom_point() +\n  stat_smooth(method = \"lm\")\n\n\n\n\nAbbildung 1.4— Zusammenhang zwischen der Anzahl an Blättern und der Anzahl an Blüten für die vier Behandlungen.\n\n\n\n\nWunderbar, jetzt können wir mit der Analyse der Outcomes anfangen. Wir rechnen als erstes die Trieblänge als eine multiple lineare Gaussian Regression. Danach dann die Anzahlen mit einer multiplen linearen Poisson Regression. Dann wollen wir noch das Compact letter display für die multiplen Vergleiche wiedergegeben haben.\n\n1.0.1 Trieblänge\nBeginnen wir damit, dass wir uns zuerst den Datensatz filtern. Wir wollen nur die Trieblänge und die achte Woche in unseren Analysedatensatz. Dann sind wir sicher, dass wir nicht ausversehen eine andere Analyse rechnen.\n\nshoot_length_tbl &lt;- cutting_tbl %&gt;% \n  filter(outcome == \"shoot\" & week == 8)\n\nWir bauen uns unser lineares Modell mit der Annahme einers normalverteilten Outcomes mit der Funktion lm(). Wir nehmen noch den Interaktionsterm für die Behandlung und Blöcke mit in das Modell.\n\nshoot_length_fit &lt;- lm(rsp ~ trt + block + trt:block, \n                       data = shoot_length_tbl)\n\nEin kurzer Blick in eine zweifaktorielle ANOVA um zu schauen ob wir überhaupt einen Behandlunsgeffekt haben und eventuell auch eine signifikante Interaktion.\n\nshoot_length_fit %&gt;% \n  anova() %&gt;% \n  model_parameters()\n\nParameter | Sum_Squares | df | Mean_Square |     F |      p\n-----------------------------------------------------------\ntrt       |     1651.86 |  3 |      550.62 | 18.45 | &lt; .001\nblock     |        1.67 |  1 |        1.67 |  0.06 | 0.816 \ntrt:block |       73.67 |  3 |       24.56 |  0.82 | 0.500 \nResiduals |      477.57 | 16 |       29.85 |       |       \n\nAnova Table (Type 1 tests)\n\n\nWir haben einen signifikanten Behandlungseffekt vorliegen und keine signifikante Interaktion zwischen der Behandlung und den Blöcken. Das ist wie wir es wollten und dann können wir noch kurz schauen, wie gut unser Experiment funktioniert hat. Wieviel Varianz können wir mit dem Behandlungen erklären? Wir berechnen dazu \\(\\eta^2\\).\n\nshoot_length_fit %&gt;% \n  eta_squared()\n\n# Effect Size for ANOVA (Type I)\n\nParameter | Eta2 (partial) |       95% CI\n-----------------------------------------\ntrt       |           0.78 | [0.55, 1.00]\nblock     |       3.49e-03 | [0.00, 1.00]\ntrt:block |           0.13 | [0.00, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\nMit einem \\(\\eta^2\\) von \\(0.78\\) können wir 78% der Varianz in unserem Experiment mit der Behandlung erklären. Das ist mehr als gut. Das spricht für ein gut geplantes und durchgeführtes Experiment.\nNachdem wir also sicher sind, dass wir etwas in den Daten haben, nutzen wir wieder das Paket emmeans um die paarweisen Vergleiche zu rechnen. Dafür legen wir erstmal wieder ein emmeans Objekt an. Wir müssen uns hier nicht um die Blöcke scheren, wir haben ja keine signifikante Interaktion vorliegen.\n\nshoot_emm_obj &lt;- shoot_length_fit %&gt;% \n  emmeans(specs = ~ trt) \n\nNOTE: Results may be misleading due to involvement in interactions\n\n\nAls nächstes rechnen wir dann schon die paarweisen Vergleiche und erhalten die Bonferroni adjustierten \\(p\\)-Werte zurück. Wenn du nicht adjustieren \\(p\\)-Werte willst, dann nehme einfach die Option adjust = \"none\".\n\nshoot_emm_obj %&gt;% \n  contrast(method = \"pairwise\", adjust = \"bonferroni\")\n\n contrast                estimate   SE df t.ratio p.value\n control - nodium_3rd       18.53 3.15 16   5.874  0.0001\n control - nodium_5th       11.22 3.15 16   3.558  0.0157\n control - strong           21.53 3.15 16   6.825  &lt;.0001\n nodium_3rd - nodium_5th    -7.31 3.15 16  -2.316  0.2049\n nodium_3rd - strong         3.00 3.15 16   0.951  1.0000\n nodium_5th - strong        10.31 3.15 16   3.267  0.0291\n\nResults are averaged over the levels of: block \nP value adjustment: bonferroni method for 6 tests \n\n\nWir können uns dann auch das compact letter display wiedergeben lassen.\n\nshoot_emm_obj %&gt;%\n  cld(Letters = letters, adjust = \"bonferroni\") \n\n trt        emmean   SE df lower.CL upper.CL .group\n strong       34.8 2.23 16     28.5     41.1  a    \n nodium_3rd   37.8 2.23 16     31.5     44.1  ab   \n nodium_5th   45.1 2.23 16     38.8     51.4   b   \n control      56.3 2.23 16     50.1     62.6    c  \n\nResults are averaged over the levels of: block \nConfidence level used: 0.95 \nConf-level adjustment: bonferroni method for 4 estimates \nP value adjustment: bonferroni method for 6 tests \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nInsbesondere in diesme Beispiel macht es auch Sinn sich nicht alle paarweisen Vergleiche anzuschauen sondern eben nur die Vergleiche zu der Kontrolle. Dafür nutzen wir dann die Methode trt.vs.ctrlk und wählen mit der Option ref = 1 unser Referenzlevel des Behandlungsfaktors. Da unsere Kontrolle schon das erste Level ist, schreiben wir also ref = 1 und erhalten die Vergleiche zu der Kontrolle.\n\nshoot_emm_obj %&gt;% \n  contrast(method = \"trt.vs.ctrlk\", ref = 1, \n           adjust = \"bonferroni\")\n\n contrast             estimate   SE df t.ratio p.value\n nodium_3rd - control    -18.5 3.15 16  -5.874  0.0001\n nodium_5th - control    -11.2 3.15 16  -3.558  0.0079\n strong - control        -21.5 3.15 16  -6.825  &lt;.0001\n\nResults are averaged over the levels of: block \nP value adjustment: bonferroni method for 3 tests \n\n\nWie wir sehen rechnen wir nur noch die Vergleiche zu der Kontrolle. Alle Vergleiche sind auch signifikant und die Kontrolle ist immer größer als die anderen Behandlungen. Wenn du das Minus gedreht haben möchtest, dann nutze reverse = TRUE als Option. Dann rechnest du Kontrolle minus den anderen Behandlungen.\nZum Abschluss können wir uns für die achte Woche noch die Barplots in der Abbildung 1.5 für die vier Behandlungen anschauen. Wir mitteln dabei über die beiden Blöcke. Wir wollen jetzt das Compact letter display noch ergänzen. Dafür bauen wir uns einen letter_vec in dem wir die richtig sortierten Buchstaben dann eintragen.\n\nletter_vec &lt;- c(\"c\", \"ab\", \"b\", \"a\")\n\nDann bauen wir uns noch ein Objekt mit den Mittelwerten und der Stndardabweichung für die vier Behandlungen.\n\nshoot_stat_tbl &lt;- shoot_length_tbl %&gt;% \n  group_by(trt) %&gt;% \n  summarise(mean = mean(rsp),\n            sd = sd(rsp))\n\nAbschließend können wir dann die Barplots mit den Fehlerbalken und dem Compact letter display darstellen. Ich habe hier mal eine rote Farbe für die Buchstaben gewählt, aber du kannst da gerne eine andere Farbe nutzen. so sieht man aber die Buchstaben auf den ersten Blick. Die Position der Buchstaben auf der y-Achse habe ich mit Try&Error dann selber rausgefunden. Geht sicherlich noch schöner, aber so ist es dann auch gut.\n\nggplot(shoot_stat_tbl, aes(x = trt, y = mean, fill = trt)) + \n  geom_bar(stat = \"identity\", position = position_dodge()) +\n  geom_errorbar(aes(ymin = mean-sd, ymax = mean+sd),\n                width = 0.2, position = position_dodge(0.9)) +\n  theme_bw() +\n  labs(y = \"Mittlere Anzahl an Blüten\",\n       x = \"\", fill = \"\") +\n  scale_fill_okabeito() +\n  annotate(\"text\", x = c(1, 2, 3, 4), c(70, 48, 55, 45),\n           label = letter_vec, size = 5, color = \"red\")\n\n\n\n\nAbbildung 1.5— Barplots der vier Behandlungen gemittelt über die Blöcke zusammen mit dem Compact letter display.\n\n\n\n\n\n\n1.0.2 Blütenanzahl\nIm Folgenden schaue ich mir nur die Blütenanzahl flowers als Outcome an. Die anderen Outcomes sind dann einfach nur Copy&Paste von dieser Analyse der Blütenanzahl. Wenn wir eine Analyse für eine Poissonregression rechnen können, dann können wir das auch ohne weiteres für die anderen beiden Outcomes.\nAls erstes filtern wir wieder die Daten. Wir wollen nur die Blüten und die achte Woche in unseren Analysedatensatz. Dann sind wir sicher, dass wir nicht ausversehen eine andere Analyse rechnen.\n\nflowers_tbl &lt;- cutting_tbl %&gt;% \n  filter(outcome == \"flower\" & week == 8)\n\nJetzt kommt der größte Unterschied. Wir rechnen kein lm() mit der implizieten Annahme eines normalverteilten Outcomes sondern ein glm() in dem wir dann die Verteilunsgfamilie des Outcomes definieren können. In unserem Fall dann für die Zähldaten die Quasipoissonverteilung. Sonst ist das Modell gleich wie ebi unserer Trieblänge.\n\nflowers_fit &lt;- glm(rsp ~ trt + block + trt:block, \n                   data = flowers_tbl, \n                   family = quasipoisson())\n\nSchauen wir uns einmal die ANOVA an. Da wir ein GLM rechnen, können wir nicht die Funktion anova() nutzen sondern müssen die Funktion Anova() aus dem R Paket car anwenden. Dann erhalten wir auch die \\(p\\)-Werte die wir wollen.\n\nflowers_fit %&gt;% \n  car::Anova() %&gt;% \n  model_parameters()\n\nParameter |  Chi2 | df |      p\n-------------------------------\ntrt       | 19.41 |  3 | &lt; .001\nblock     |  0.49 |  1 | 0.484 \ntrt:block |  1.80 |  3 | 0.615 \n\nAnova Table (Type 2 tests)\n\n\nIm Prinzip das gleiche Ergebnis wie schon bei der Trieblänge. Wir haben einen signifikanten Effekt der Behandlung auf die Blütenanzahl und keine signifikante Interaktion. Wir rechnen also mit dem Modell jetzt weiter. Wiederum nutzen wir das R Paket emmeans. Wichtig ist hier, dass wir als Typ dann die response angeben. Sonst erhalten wir alle Effektschätzer auf der Link-Scale und die Link-Scale können wir dann nicht interpretieren.\n\nflowers_emm_obj &lt;- flowers_fit %&gt;% \n  emmeans(specs = ~ trt, type = \"response\") \n\nWir machen auch hier wieder so weiter wie schon bei der Treiblänge. Einmal die paarweisen Vergleiche mit Bonferroni adjustierten \\(p\\)-Werten.\n\nflowers_emm_obj %&gt;% \n  contrast(method = \"pairwise\", adjust = \"bonferroni\") \n\n contrast                ratio    SE  df null z.ratio p.value\n control / nodium_3rd    1.702 0.444 Inf    1   2.037  0.2498\n control / nodium_5th    1.087 0.249 Inf    1   0.363  1.0000\n control / strong        3.278 1.081 Inf    1   3.601  0.0019\n nodium_3rd / nodium_5th 0.639 0.169 Inf    1  -1.698  0.5374\n nodium_3rd / strong     1.926 0.683 Inf    1   1.847  0.3883\n nodium_5th / strong     3.016 1.002 Inf    1   3.323  0.0053\n\nResults are averaged over the levels of: block \nP value adjustment: bonferroni method for 6 tests \nTests are performed on the log scale \n\n\nDann lassen wir uns noch das Compact letter display für die Blütennzahl wiedergeben.\n\nflowers_emm_obj %&gt;%\n  cld(Letters = letters, adjust = \"bonferroni\") \n\n trt         rate   SE  df asymp.LCL asymp.UCL .group\n strong      8.91 2.57 Inf      4.34      18.3  a    \n nodium_3rd 17.16 3.54 Inf     10.24      28.7  ab   \n nodium_5th 26.88 4.43 Inf     17.81      40.6   b   \n control    29.21 4.67 Inf     19.60      43.5   b   \n\nResults are averaged over the levels of: block \nConfidence level used: 0.95 \nConf-level adjustment: bonferroni method for 4 estimates \nIntervals are back-transformed from the log scale \nP value adjustment: bonferroni method for 6 tests \nTests are performed on the log scale \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nAuch hier könnten wir nur zu der Kontrolle vergleichen, wenn wir das wollen würden. Hier ist aber das Rüchschneiden nicht so signifikant wie bei der Trieblänge. Hier sehen wir dann auch die Rate der Blüten. Wir haben also im Verhätnis zur Kontrolle nur knapp die Häfte an Blüten bei der Behandlung nodium_3rd und fast nur ein Drittel der Anzahl an Blüten bei der Behandlung strong.\n\nflowers_emm_obj %&gt;% \n  contrast(method = \"trt.vs.ctrlk\", ref = 1, \n           adjust = \"bonferroni\")\n\n contrast             ratio    SE  df null z.ratio p.value\n nodium_3rd / control 0.587 0.153 Inf    1  -2.037  0.1249\n nodium_5th / control 0.920 0.211 Inf    1  -0.363  1.0000\n strong / control     0.305 0.101 Inf    1  -3.601  0.0010\n\nResults are averaged over the levels of: block \nP value adjustment: bonferroni method for 3 tests \nTests are performed on the log scale \n\n\nJetzt kannst du den R Code im Prinzip auch nochmal für die zwei anderen Outcomes durchführen."
  },
  {
    "objectID": "example-analysis-02.html",
    "href": "example-analysis-02.html",
    "title": "2  Einen TukeyHSD Test rechnen",
    "section": "",
    "text": "Letzte Änderung am 13. January 2024 um 17:46:55\n\n\n\n\n\n\n\nGenutzte R Pakete\n\n\n\n\npacman::p_load(tidyverse, magrittr, readxl, \n               multcompView)\n\n\n\nIn diesem sehr kurzen Beispiel wollen wir uns einem den Tukey Test anschauen. Eigentlich ist es der Tukey HSD Test für Tukey Honest Significant Differences. Die von dieser Funktion zurückgegebenen \\(p\\)-Werte und 95% Konfidenzintervalle basieren auf der t-Test Verteilung. Wir nehmen also ein normalverteiltes Outcome \\(y\\) sowie eine homogene Varianz an.\nDie auf diese Weise konstruierten 95% Konfidenzintervalle gelten nur für balancierte Designs, bei denen in jedem Level des Faktors die gleiche Anzahl von Beobachtungen gemacht wird. Die Funktion TukeyHSD() enthält eine Anpassung für den Stichprobenumfang, die sinnvolle 95% Konfidenzintervalle für leicht unbalancierte Designs erzeugt. Ja, und da geht es schon wieder los. Was heißt sinnvoll? Oder andersherum, was ist eine leichte Abweichung? Deshalb mag ich persönlich nicht die Funktion TukeyHSD() und ziehe das R Paket emmeans vor. Du siehst auch in den anderen Beispielen immer die Anwendung von emmeans.\nAber gut, hier soll es ja um den Tukey Test gehen. Also wir nehmen uns einmal ein simples Beispiel mit verschiedenen Bodenarten und dann wollen wir als Outcome \\(y\\) die Pflanzenhöhe miteinander vergleichen.\n\nsoil_tbl &lt;- read_excel(\"data/soil_1fac_data.xlsx\") %&gt;% \n  mutate(variante = as_factor(variante)) %&gt;% \n  select(variante, height)\n\nDie Funktion TukeyHSD() ist alt. Deshalb kann die Funktion nur den Modellfit aus der Funktion aov() verarbeiten. Die Funktion aov() wiederum ist eigentlich nur eine Funktion, die die beiden Funktionen anova() und lm() in ungünstiger Art und Weise kombiniert. Aber gut, geht eben nicht anders.\n\naov_fit &lt;- aov(height ~ variante, data = soil_tbl)\n\nDann können wir den Modellfit in die Funktion TukeyHSD() stecken und benutzen. Wir kriegen eine etwas seltsame Ausgabe, aber wir wollen auch hier dann weiter zu dem compact letter display.\n\ntukey_obj &lt;- aov_fit %&gt;% \n  TukeyHSD()\n\nDas compact letter display können wir über die Funktion multcompLetters() erstellen. Wir müssen dafür die \\(p\\)-Werte extrahieren und dann an die Funktion weiterleiten. Hier ist wichtig, dass wir nur adjustierte \\(p\\)-Werte wiederbekommen. Wenn du unadjustierte \\(p\\)-Werte möchtest, dann musst du nochmal in die Funktion emmeans() schauen.\n\ntukey_obj %&gt;% \n  pluck(\"variante\") %&gt;% \n  magrittr::extract( , \"p adj\") %&gt;% \n  multcompLetters()\n\n         Torf Kompostiertes  Gehäckseltes Aufgefasertes    Holzfasern \n         \"ab\"          \"ab\"           \"a\"          \"ab\"           \"b\" \n\n\nMehr zum compact letter display und der Interpretation kannst du im Kapitel zu Multiple Vergleiche oder Post-hoc Tests nachlesen. Dort findest du auch eine Alternative zu dem Tukey Test."
  },
  {
    "objectID": "example-analysis-03.html",
    "href": "example-analysis-03.html",
    "title": "3  Spurenelemente in Spinatblättern und Stielen",
    "section": "",
    "text": "Letzte Änderung am 13. January 2024 um 17:48:12\n\n\n\n\n\n\n\nGenutzte R Pakete\n\n\n\n\npacman::p_load(tidyverse, magrittr, readxl, see, janitor,\n               effectsize, emmeans, multcomp, psych,\n               parameters, scales,\n               #psych, parameters, effectsize, emmeans,\n               #multcomp, \n               conflicted)\n## resolve some conflicts with same function naming\nconflict_prefer(\"select\", \"dplyr\")\nconflict_prefer(\"filter\", \"dplyr\")\n\n\n\nIn der folgenden Datenanalyse schauen wir uns die Konzentrationen von den Spurenelementen Fe, Cd und Zn in Spinat an. Dabei haben wir zum einen in den Blätter und zum anderen in den Stielen gemessen. Daher haben wir insgesamt drei Outcomes an zwei Orten und somit sechs Kombinationen auszuwerten. Wir haben uns darüber hinaus noch sieben Behandlungen in je vier Blöcken als Wiederholung angeschaut. Laden wir also einmal die Daten.\n\nspinach_tbl &lt;- read_excel(\"data/spinach_metal_data.xlsx\") %&gt;% \n  mutate(trt = as_factor(trt),\n         sample = as_factor(sample),\n         block = as_factor(block))\n\nWir haben die Daten im Wide-Format vorliegen, daher müssen wir die Daten über die Funktion pivot_longer() noch in das Long-Format umwandeln. Zum einen brauchen wir das Long-Format für unsere Abbildungen und zum anderen dann auch für unsere Analysen.\n\nspinach_plot_tbl &lt;- spinach_tbl %&gt;% \n  pivot_longer(cols = fe:zn,\n               names_to = \"outcome\",\n               values_to = \"rsp\") %&gt;% \n  mutate(outcome = as_factor(outcome))\n\nspinach_plot_tbl %&gt;% \n  head\n\n# A tibble: 6 × 5\n  trt   sample block outcome     rsp\n  &lt;fct&gt; &lt;fct&gt;  &lt;fct&gt; &lt;fct&gt;     &lt;dbl&gt;\n1 1     leaf   1     fe      16.9   \n2 1     leaf   1     cd       9.28  \n3 1     leaf   1     zn       0.127 \n4 1     stem   1     fe       7.95  \n5 1     stem   1     cd       7.97  \n6 1     stem   1     zn       0.0579\n\n\nWir sehen, dass wir für jede Outcome/Sample Kombination ein zweifaktorielles Modell für Behandlung und Block rechnen müssen. Schauen wir uns zuerst wie immer einmal die Abbildung 3.1 in ggplot() an und machen dann mit der Auswertung weiter.\n\nggplot(spinach_plot_tbl, aes(trt, rsp, shape = block, color = trt)) +\n  theme_minimal() +\n  geom_jitter() +\n  facet_wrap(~ outcome*sample, scales = \"free_y\", ncol = 2) +\n  labs(x = \"Behandlung\", y = \"Gemessenes Outcome\",\n       shape = \"Block\", color = \"Behandlung\") +\n  scale_color_okabeito()\n\n\n\n\nAbbildung 3.1— Abbildung der drei Outcomes in den zwei Samples für die sieben Behandlungen in jeweils vier Blöcken.\n\n\n\n\nDa wir nur eine Beobachtung je Block/Behandlung Kombination haben, können wir später keine Interaktion rechnen. Wir bräiuchten dafür Wiederholungen auf der Ebene der Blöcke. Also nicht nur eine Pflanze pro Block und Behandlung. Im Folgenden gibt es einmal die umständliche Copy&Paste Variante und einmal die etwas komplexere Lösung über map() und nest().\n\n3.0.1 Eisen (Fe) und Blatt\nMachen wir es uns erstmal einfach. Wir müssen ja für jede der sechs Outcome/Sample Kombinationen eine ANOVA rechnen, dann rechnen wir einen multiplen Vergleich und lassen uns das Compact letter display wiedergeben. Das machen wir jetzt alles einmal für die Kombination Eisen und Blatt.\nAlso brauchen wir als erstes unseren Datensatz mit nur dem Outcome gleich fe und das Sample gleich leaf. Das Selektieren machen wir dann über die Funktion filter().\n\nfe_leaf_tbl &lt;- spinach_plot_tbl %&gt;% \n  filter(outcome == \"fe\" & sample == \"leaf\")\n\nDan müssen wir das lineare Modell schätzen. Das Schätzen der Koeffizienten übernimmt wie immer die Funktion lm(). Wir nehmen hier an, dass unsere Konzentrationen ungefähr normalverteilt sind. Wir können den Interaktionsterm trt:block nicht mit ins Modell nehmen, da wir nur eine Beobachtung je Behandlung/Block Kombination haben.\n\nfe_leaf_fit &lt;- lm(rsp ~ trt + block, data = fe_leaf_tbl)\n\nJetzt können wir die ANOVA rechnen und schauen was wir da haben.\n\nfe_leaf_fit %&gt;% anova()\n\nAnalysis of Variance Table\n\nResponse: rsp\n          Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \ntrt        6 1015.45 169.242 19.0531 6.759e-07 ***\nblock      3   84.35  28.117  3.1654   0.04975 *  \nResiduals 18  159.89   8.883                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWir haben einen ganz schwachen signifikanten Effekt des Blocks und einen starken signifikanten Effekt der Behandlung. Der Effekt des Blocks ist nicht so schön, wir würden eigentlich erwarten, dass der Block keinen Effekt hat. Wir haben ja die Zuordnung der Behandlungen zu den Blöcken zufällig durchgeführt. Da sollte also eigentlich kein Effekt des Blocks auftreten. Schauen wir nochmal wie stark die Effekte sind in dem wir uns das \\(\\eta^2\\) berechnen.\n\nfe_leaf_fit %&gt;% eta_squared()\n\n# Effect Size for ANOVA (Type I)\n\nParameter | Eta2 (partial) |       95% CI\n-----------------------------------------\ntrt       |           0.86 | [0.73, 1.00]\nblock     |           0.35 | [0.00, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\nDer Effekt der behandlung it auf jeden Fall größer als der Effelt des Blocks. Gut 86% der Vrainz wird durch die Behandlung erklärt, dass passt dann soweit.\nWir rechnen jetzt mit der Funktion emmeans() weiter und berücksichtigen dabei die unterschiedlichen Mittelwerte der Blöcke für die einzelnen Behandlungen.\n\nfe_leaf_emm &lt;- fe_leaf_fit %&gt;% \n  emmeans(~ trt)\n\nJetzt können wir un die paarweisen Vergleich über die Funktion contrast() wiedergeben lassen. Wir sehen, dass wir einiges an signifikanten Ergebnissen vorliegen haben. Du kannst die Ausgabe in ein Tibble mit as_tibble() umwandeln und dir dann mit der Funktion print(n = 21) alle Zeilen ausgeben lassen.\n\nfe_leaf_emm %&gt;% \n  contrast(method = \"pairwise\", adjust = \"bonferroni\") \n\n contrast    estimate   SE df t.ratio p.value\n trt1 - trt2   -7.844 2.11 18  -3.722  0.0328\n trt1 - trt3  -12.156 2.11 18  -5.768  0.0004\n trt1 - trt4  -17.429 2.11 18  -8.270  &lt;.0001\n trt1 - trt5  -11.218 2.11 18  -5.323  0.0010\n trt1 - trt6  -16.877 2.11 18  -8.008  &lt;.0001\n trt1 - trt7  -18.222 2.11 18  -8.646  &lt;.0001\n trt2 - trt3   -4.312 2.11 18  -2.046  1.0000\n trt2 - trt4   -9.585 2.11 18  -4.548  0.0052\n trt2 - trt5   -3.374 2.11 18  -1.601  1.0000\n trt2 - trt6   -9.033 2.11 18  -4.286  0.0093\n trt2 - trt7  -10.378 2.11 18  -4.924  0.0023\n trt3 - trt4   -5.273 2.11 18  -2.502  0.4664\n trt3 - trt5    0.938 2.11 18   0.445  1.0000\n trt3 - trt6   -4.721 2.11 18  -2.240  0.7970\n trt3 - trt7   -6.066 2.11 18  -2.878  0.2101\n trt4 - trt5    6.211 2.11 18   2.947  0.1809\n trt4 - trt6    0.552 2.11 18   0.262  1.0000\n trt4 - trt7   -0.793 2.11 18  -0.376  1.0000\n trt5 - trt6   -5.659 2.11 18  -2.685  0.3175\n trt5 - trt7   -7.004 2.11 18  -3.323  0.0794\n trt6 - trt7   -1.345 2.11 18  -0.638  1.0000\n\nResults are averaged over the levels of: block \nP value adjustment: bonferroni method for 21 tests \n\n\nSchauen wir uns für diesen Vergleich dann noch das Compact letter display an. Bitte beachte, dass du dir mit der Funktion arrange() immer die Reihenfolge der Behandlungen ausgeben lassen kannst. Sonst ist die Ausgabe nach der Spalte .group sortiert und nicht nach den Behandlungen. Wenn die Buchstaben nicht gleich sind, dann unterscheiden sich die Behandlungen.\n\nfe_leaf_emm %&gt;%\n  cld(Letters = letters, adjust = \"none\") %&gt;% \n  arrange(trt)\n\n trt emmean   SE df lower.CL upper.CL .group\n 1     11.8 1.49 18     8.66     14.9  a    \n 2     19.6 1.49 18    16.50     22.8   b   \n 3     23.9 1.49 18    20.81     27.1   b   \n 4     29.2 1.49 18    26.09     32.3    c  \n 5     23.0 1.49 18    19.88     26.1   b   \n 6     28.7 1.49 18    25.53     31.8    c  \n 7     30.0 1.49 18    26.88     33.1    c  \n\nResults are averaged over the levels of: block \nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same. \n\n\nAuch hier schauen wir uns einmal die Korrelation zwischen den Outcomes in der Abbildung 3.2 an. Wir sehen in der Abbildung 3.2 (a) die Korrelation zwischen den beiden Outcomes Fe und Zn zusammen in den Blättern und den Stielen. Wir würden meinen, dass wir eine positive Korrelation vorliegen haben. Wir sehen, dass mit mehr Zn auch mehr Fe auftritt. Was uns aber etwas stutzig werden lässt, sind die beiden Punktewolken in der linken unteren Abbildung. Daher einmal schnell aufgetrennt für die Blätter in Abbildung 3.2 (b) und für die Stiele in Abbildung 3.2 (c). Wir sehen, dass wir nichts sehen. Denn getrennt für die Blätter und Stiele haben wir dann keine Korrelation mehr für die beiden Outcomes vorliegen.\n\nspinach_tbl %&gt;% \n  select(fe, zn) %&gt;% \n  pairs.panels(smooth = TRUE, density = TRUE, method = \"kendall\", lm = TRUE, \n               cor = TRUE, ellipses = FALSE, stars = TRUE) \n\nspinach_tbl %&gt;% \n  filter(sample == \"leaf\") %&gt;% \n  select(fe, zn) %&gt;% \n  pairs.panels(smooth = TRUE, density = TRUE, method = \"kendall\", lm = TRUE, \n               cor = TRUE, ellipses = FALSE, stars = TRUE)    \n\nspinach_tbl %&gt;% \n  filter(sample == \"stem\") %&gt;% \n  select(fe, zn) %&gt;% \n  pairs.panels(smooth = TRUE, density = TRUE, method = \"kendall\", lm = TRUE, \n               cor = TRUE, ellipses = FALSE, stars = TRUE) \n\n\n\n\n\n\n\n(a) Blätter und Stiele.\n\n\n\n\n\n\n\n(b) Nur Blätter.\n\n\n\n\n\n\n\n(c) Nur Stiele.\n\n\n\n\nAbbildung 3.2— Korrelation und Verteilung zwischen den Outcomes Fe und Zn.\n\n\n\n\n\n3.0.2 Und alles aufeinmal…\nNun gut, jetzt haben wir unsere Analyse für das Blatt und den Eisengehalt gerechnet. Wir müssten jetzt die Analyse nochmal für alle anderen fünf Kombinationen durchführen. Das würde einiges an Zeit kosten und auch sehr viel Copy&Paste Aufwand. Kann man machen, aber wir können die Analyse auch in einem Rutsch durchführen. Dafür nutzen wir die Funktion nest() und dann anschließend die Funktion map() um auf den genesteten Daten die Analysen zu rechnen.\nIm ersten Schritt müssen wir unsere Daten gruppieren. Wir haben dann die sechs Kombinationen aus Outcome und Sample vorliegen. Dann nesten wir den Datensatz in sechs Zeilen. Wir klappen sozusagen die Daten für jede der sechs Kombinationen zusammen. Alles fällt dann in eine Zelle zusammen.\n\nspinach_nest_tbl &lt;- spinach_plot_tbl %&gt;% \n  group_by(sample, outcome) %&gt;% \n  nest() \n\nSchauen wir uns den genesteten Datensatz einmal an. Wir sehen, dass wir die gesamten Daten in der Spalte data zusammengefaltet haben. Wir haben also sechs Tibbles mit den Daten der jeweiligen Outcome/Sample Kombinationen in der Spalte data vorliegen.\n\nspinach_nest_tbl \n\n# A tibble: 6 × 3\n# Groups:   sample, outcome [6]\n  sample outcome data             \n  &lt;fct&gt;  &lt;fct&gt;   &lt;list&gt;           \n1 leaf   fe      &lt;tibble [28 × 3]&gt;\n2 leaf   cd      &lt;tibble [28 × 3]&gt;\n3 leaf   zn      &lt;tibble [28 × 3]&gt;\n4 stem   fe      &lt;tibble [28 × 3]&gt;\n5 stem   cd      &lt;tibble [28 × 3]&gt;\n6 stem   zn      &lt;tibble [28 × 3]&gt;\n\n\nWir können jetzt auf den Tibbles in der Spalte data weiter rechnen. Wir nutzen für das Weiterrechnen die Funktion map(), die in jeder Zeile der Spalte .data die gleiche Funktion ausführt. Unser Ergebnis speichern wir dann in einer neuen Spalte und dafür nutzen wir die Funktion mutate().\nKonkret erstellen wir uns jetzt eine neue Spalte model in der das lineare Modell der Funktion lm() abliegt.\n\nspinach_model_tbl &lt;- spinach_nest_tbl %&gt;%\n  mutate(model = map(data, ~lm(rsp ~ trt + block, data = .x))) \n\nIm weiteren Schritt rechnen wir jetzt auf der Spalte model eine ANOVA und lassen uns dann die schönere Ausgabe über die Funktion model_parameters() wiedergeben. Der wichtigste Tiel ist die Funktion unnest() die uns die Zellen mit den ANOVA Ergebnissen dann wieder ausklappt. Der Rest ist dann noch filtern und anpassen. Ich möchte das die Ausgabe reduziert ist und die p-Werte sollen auch schön formatiert werden.\n\nspinach_model_tbl %&gt;% \n  mutate(anova = map(model, anova)) %&gt;% \n  mutate(parameter = map(anova, model_parameters)) %&gt;% \n  select(sample, outcome, parameter) %&gt;% \n  unnest(parameter) %&gt;% \n  filter(Parameter != \"Residuals\") %&gt;% \n  select(sample, outcome, Parameter, p) %&gt;% \n  mutate(p = pvalue(p))\n\n# A tibble: 12 × 4\n# Groups:   sample, outcome [6]\n   sample outcome Parameter p     \n   &lt;fct&gt;  &lt;fct&gt;   &lt;chr&gt;     &lt;chr&gt; \n 1 leaf   fe      trt       &lt;0.001\n 2 leaf   fe      block     0.050 \n 3 leaf   cd      trt       0.047 \n 4 leaf   cd      block     &lt;0.001\n 5 leaf   zn      trt       0.424 \n 6 leaf   zn      block     0.290 \n 7 stem   fe      trt       0.021 \n 8 stem   fe      block     0.016 \n 9 stem   cd      trt       0.325 \n10 stem   cd      block     &lt;0.001\n11 stem   zn      trt       0.512 \n12 stem   zn      block     &lt;0.001\n\n\nAuch können wir un die \\(\\eta^2\\) für die Modelle berechnen lassen. Die Funktion unnest() klappt uns dann die Ergebnisse wieder aus. Dann müssen wir noch etwas aufräumen und schon haben wir für alle Kombinationen dann den Anteil der erklärten Varianz.\n\nspinach_model_tbl %&gt;%  \n  mutate(eta = map(model, eta_squared)) %&gt;% \n  unnest(eta) %&gt;% \n  clean_names() %&gt;% \n  select(sample, outcome, eta2_partial) \n\n# A tibble: 12 × 3\n# Groups:   sample, outcome [6]\n   sample outcome eta2_partial\n   &lt;fct&gt;  &lt;fct&gt;          &lt;dbl&gt;\n 1 leaf   fe             0.864\n 2 leaf   fe             0.345\n 3 leaf   cd             0.475\n 4 leaf   cd             0.775\n 5 leaf   zn             0.260\n 6 leaf   zn             0.183\n 7 stem   fe             0.529\n 8 stem   fe             0.430\n 9 stem   cd             0.295\n10 stem   cd             0.652\n11 stem   zn             0.232\n12 stem   zn             0.589\n\n\nIm letzten Schritt bauen wir uns die Spalten für die Funktion emmeans(), dann die Kontraste und das Compact letter display. Hier nutzen wir die Schreibweise map(&lt;Spalte&gt;, &lt;Funktion&gt;, &lt;Optionen&gt;). Daher definieren wir erst welche Spalte map() bearbeiten soll. Dann die Funktion die map() nutzen soll und anschließend die Optionen für die Funktion. Wir können hier auch mehrere Optionen nacheinander angeben.\n\nspinach_emm_tbl &lt;- spinach_model_tbl %&gt;%  \n  mutate(emm = map(model, emmeans, ~trt)) %&gt;% \n  mutate(contrast = map(emm, contrast, method = \"pairwise\", \n                        adjust = \"none\")) %&gt;% \n  mutate(cld = map(emm, cld, Letters = letters, adjust = \"none\"))\n\nJetzt lassen wir uns die Spalte contrast wiedergeben. Wir müssen aber vorher die Spalte noch in ein Tibble umwandeln. Dann wollen wir noch die p-Werte schöner haben. Wichtig ist auch immer, dass wir über die Funktion select() die für uns wichtigen Spalten auswählen.\n\nspinach_emm_tbl %&gt;% \n  mutate(contrast = map(contrast, as_tibble)) %&gt;% \n  unnest(contrast) %&gt;% \n  select(sample, outcome, contrast, p.value) %&gt;% \n  mutate(p.value = pvalue(p.value))\n\n# A tibble: 126 × 4\n# Groups:   sample, outcome [6]\n   sample outcome contrast    p.value\n   &lt;fct&gt;  &lt;fct&gt;   &lt;chr&gt;       &lt;chr&gt;  \n 1 leaf   fe      trt1 - trt2 0.002  \n 2 leaf   fe      trt1 - trt3 &lt;0.001 \n 3 leaf   fe      trt1 - trt4 &lt;0.001 \n 4 leaf   fe      trt1 - trt5 &lt;0.001 \n 5 leaf   fe      trt1 - trt6 &lt;0.001 \n 6 leaf   fe      trt1 - trt7 &lt;0.001 \n 7 leaf   fe      trt2 - trt3 0.056  \n 8 leaf   fe      trt2 - trt4 &lt;0.001 \n 9 leaf   fe      trt2 - trt5 0.127  \n10 leaf   fe      trt2 - trt6 &lt;0.001 \n# ℹ 116 more rows\n\n\nNachdem wir uns die Kontraste für die paarweisen Vergleiche wiedergeben haben lassen, wollen wir jetzt noch die ganzen Compact letter displays haben. Auch hier nutzen wir dann die Funktion unnest() und wolle dann nicht alle Spalten haben.\n\nspinach_emm_tbl %&gt;% \n  mutate(cld = map(cld, arrange, trt)) %&gt;% \n  unnest(cld) %&gt;% \n  select(sample, outcome, trt, .group) %&gt;% \n  print(n = 15)\n\n# A tibble: 42 × 4\n# Groups:   sample, outcome [6]\n   sample outcome trt   .group\n   &lt;fct&gt;  &lt;fct&gt;   &lt;fct&gt; &lt;chr&gt; \n 1 leaf   fe      1     \" a  \"\n 2 leaf   fe      2     \"  b \"\n 3 leaf   fe      3     \"  b \"\n 4 leaf   fe      4     \"   c\"\n 5 leaf   fe      5     \"  b \"\n 6 leaf   fe      6     \"   c\"\n 7 leaf   fe      7     \"   c\"\n 8 leaf   cd      1     \" a  \"\n 9 leaf   cd      2     \"  bc\"\n10 leaf   cd      3     \"  bc\"\n11 leaf   cd      4     \" ab \"\n12 leaf   cd      5     \"   c\"\n13 leaf   cd      6     \" abc\"\n14 leaf   cd      7     \"  bc\"\n15 leaf   zn      1     \" a\"  \n# ℹ 27 more rows\n\n\nMit der Option print(n = 15) kannst du dir die ersten fünfzehn Zeilen ausgeben lassen. du musst also schauen, wie viele Zeilen dein Tibble hat und dann kannst du dir das ganze Tibble über die Funktion print() ausgeben lassen. Ich nutze immer diese Art der Ausgabe mit print() da es sicherer ist, als sich immer den ganzen Datensatz wiedergeben zu lassen. Mit sicherer meine ich, dass ich mir nicht die ganze R Console mit der Ausgabe zubaue."
  },
  {
    "objectID": "example-analysis-04.html#barplot-mit-compact-letter-display-und-abspeichern",
    "href": "example-analysis-04.html#barplot-mit-compact-letter-display-und-abspeichern",
    "title": "4  Steuerung der vegetativen Entwicklung krautiger Pflanzen (44B0608) - Teil 1",
    "section": "4.1 Barplot mit compact letter display und abspeichern",
    "text": "4.1 Barplot mit compact letter display und abspeichern\n\nstat_tbl &lt;- basi_tbl %&gt;% \n  group_by(versuchsgruppe) %&gt;% \n  summarise(mean = mean(frischmasse),\n            sd = sd(frischmasse),\n            se = sd/sqrt(n()))\n\n\nggplot(stat_tbl, aes(x = versuchsgruppe, y = mean, \n                     fill = versuchsgruppe)) + \n  theme_bw() +\n  geom_bar(stat = \"identity\") +\n  geom_errorbar(aes(ymin = mean-sd, ymax = mean+sd),\n                width = 0.2) +\n  labs(x = \"Versuchsgruppe\", y = \"Frischmasse in [g]\") +\n  theme(legend.position = \"none\") +\n  scale_fill_okabeito() +\n  annotate(\"text\", \n           x = 1:4, \n           y = c(19, 31, 27, 37), \n           label = c(\"a\", \"bc\", \"b\", \"c\")) +\n  annotate(\"text\", x = 1, y = 35,\n           label = \"ANOVA = &lt;0.001\", size = 3)\nggsave(\"img/barplot_frischmasse.png\", \n       width = 5, height = 3)\n\n\n\n\nAbbildung 4.1— Korrelation zwischen den beiden Jahren der Messung.\n\n\n\n\n\nggsave(\"img/barplot_trockenmasse.png\", \n       width = 5, height = 3)\n\n\nbasi_time_tbl &lt;- basi_tbl %&gt;% \n  select(versuchsgruppe, t1:t4) %&gt;% \n  pivot_longer(cols = t1:t4,\n               values_to = \"values\",\n               names_to = \"timepoint\") %&gt;% \n  mutate(timepoint = as_factor(timepoint),\n         time_num = as.numeric(timepoint))\n\n\nggplot(basi_time_tbl, aes(time_num, values, color = versuchsgruppe)) +\n  theme_bw() +\n  scale_color_okabeito() +\n  geom_jitter(position=position_dodge(0.3), shape = 4) +\n  stat_summary(fun.data=\"mean_sdl\", , fun.args = list(mult = 1), \n               geom=\"pointrange\", position=position_dodge(0.3))  +\n  stat_summary(fun = \"mean\", fun.min = \"min\", fun.max = \"max\", geom = \"line\",\n               position=position_dodge(0.3)) +\n  theme(legend.position = c(0.8, 0.2),\n        legend.background = element_rect(color=\"black\", \n                                         size=0.5, linetype=\"solid\"))\n\n\n\n\nAbbildung 4.2— Korrelation zwischen den beiden Jahren der Messung.\n\n\n\n\n\nbasi_time_fit &lt;- lm(values ~ versuchsgruppe + timepoint + versuchsgruppe:timepoint, basi_time_tbl)\n\n\nbasi_time_fit %&gt;% \n  emmeans(specs = ~ versuchsgruppe | timepoint) %&gt;% \n  contrast(method = \"pairwise\", adjust = \"none\") %&gt;% \n  as_tibble %&gt;% \n  select(contrast, timepoint, p.value) %&gt;% \n  mutate(p.value = format.pval(p.value, eps = 0.001, digits = 2)) %&gt;% \n  print(n = Inf)\n\n# A tibble: 24 × 3\n   contrast                              timepoint p.value\n   &lt;fct&gt;                                 &lt;fct&gt;     &lt;chr&gt;  \n 1 Erde - (Erde+Fließ)                   t1        0.2265 \n 2 Erde - (Erde+Perlite)                 t1        0.2265 \n 3 Erde - (Erde+Perlite+Fließ)           t1        0.0053 \n 4 (Erde+Fließ) - (Erde+Perlite)         t1        1.0000 \n 5 (Erde+Fließ) - (Erde+Perlite+Fließ)   t1        0.1007 \n 6 (Erde+Perlite) - (Erde+Perlite+Fließ) t1        0.1007 \n 7 Erde - (Erde+Fließ)                   t2        0.9119 \n 8 Erde - (Erde+Perlite)                 t2        0.0499 \n 9 Erde - (Erde+Perlite+Fließ)           t2        0.1538 \n10 (Erde+Fließ) - (Erde+Perlite)         t2        0.0388 \n11 (Erde+Fließ) - (Erde+Perlite+Fließ)   t2        0.1250 \n12 (Erde+Perlite) - (Erde+Perlite+Fließ) t2        0.5807 \n13 Erde - (Erde+Fließ)                   t3        0.8250 \n14 Erde - (Erde+Perlite)                 t3        0.0388 \n15 Erde - (Erde+Perlite+Fließ)           t3        0.2710 \n16 (Erde+Fließ) - (Erde+Perlite)         t3        0.0229 \n17 (Erde+Fließ) - (Erde+Perlite+Fließ)   t3        0.1875 \n18 (Erde+Perlite) - (Erde+Perlite+Fließ) t3        0.3214 \n19 Erde - (Erde+Fließ)                   t4        0.1007 \n20 Erde - (Erde+Perlite)                 t4        0.2710 \n21 Erde - (Erde+Perlite+Fließ)           t4        0.7402 \n22 (Erde+Fließ) - (Erde+Perlite)         t4        0.0072 \n23 (Erde+Fließ) - (Erde+Perlite+Fließ)   t4        0.1875 \n24 (Erde+Perlite) - (Erde+Perlite+Fließ) t4        0.1538 \n\n\n\nbasi_time_fit %&gt;% \n  emmeans(specs = ~ versuchsgruppe | timepoint) %&gt;%\n  cld(Letters = letters, adjust = \"none\") \n\ntimepoint = t1:\n versuchsgruppe     emmean   SE df lower.CL upper.CL .group\n Erde                 15.0 1.27 64     12.5     17.5  a    \n Erde+Perlite         17.2 1.27 64     14.7     19.7  ab   \n Erde+Fließ           17.2 1.27 64     14.7     19.7  ab   \n Erde+Perlite+Fließ   20.2 1.27 64     17.7     22.7   b   \n\ntimepoint = t2:\n versuchsgruppe     emmean   SE df lower.CL upper.CL .group\n Erde+Fließ           19.8 1.27 64     17.3     22.3  a    \n Erde                 20.0 1.27 64     17.5     22.5  a    \n Erde+Perlite+Fließ   22.6 1.27 64     20.1     25.1  ab   \n Erde+Perlite         23.6 1.27 64     21.1     26.1   b   \n\ntimepoint = t3:\n versuchsgruppe     emmean   SE df lower.CL upper.CL .group\n Erde+Fließ           20.4 1.27 64     17.9     22.9  a    \n Erde                 20.8 1.27 64     18.3     23.3  a    \n Erde+Perlite+Fließ   22.8 1.27 64     20.3     25.3  ab   \n Erde+Perlite         24.6 1.27 64     22.1     27.1   b   \n\ntimepoint = t4:\n versuchsgruppe     emmean   SE df lower.CL upper.CL .group\n Erde+Fließ           20.2 1.27 64     17.7     22.7  a    \n Erde+Perlite+Fließ   22.6 1.27 64     20.1     25.1  ab   \n Erde                 23.2 1.27 64     20.7     25.7  ab   \n Erde+Perlite         25.2 1.27 64     22.7     27.7   b   \n\nConfidence level used: 0.95 \nsignificance level used: alpha = 0.05 \nNOTE: If two or more means share the same grouping symbol,\n      then we cannot show them to be different.\n      But we also did not show them to be the same."
  },
  {
    "objectID": "example-analysis-05.html",
    "href": "example-analysis-05.html",
    "title": "5  Steuerung der vegetativen Entwicklung krautiger Pflanzen (44B0608) - Teil 2",
    "section": "",
    "text": "Letzte Änderung am 13. January 2024 um 17:52:11\n\n\n\n\n\n\n\nGenutzte R Pakete\n\n\n\n\npacman::p_load(tidyverse, readxl, parameters,\n               effectsize, magrittr, multcomp,\n               multcompView, rcompanion, rstatix,\n               emmeans, see, performance, janitor,\n               patchwork, \n               conflicted)\n## resolve some conflicts with same function naming\nconflicts_prefer(dplyr::select)\nconflicts_prefer(dplyr::filter)\nconflicts_prefer(effectsize::eta_squared)\n\n\n\nEs geht hier um das Modul Steuerung der vegetativen Entwicklung krautiger Pflanzen (44B0608)\n\ngurke_raw_tbl &lt;- read_excel(\"data/wachstum_gurke.xlsx\") %&gt;% \n  clean_names() %&gt;% \n  mutate(versuchsgruppe = as_factor(versuchsgruppe),\n         erntegewicht = ifelse(erntegewicht == 0, yes = NA, no = erntegewicht))\n\n\ngurke_len_tbl &lt;- gurke_raw_tbl %&gt;% \n  filter(str_detect(versuchsgruppe, \"L$\")) %&gt;% \n  mutate(versuchsgruppe = factor(versuchsgruppe, \n                                 labels = c(\"Proloog\", \"Quarto\", \"Katrina\")))\n\ngurke_dia_tbl &lt;- gurke_raw_tbl %&gt;% \n  filter(str_detect(versuchsgruppe, \"D$\")) %&gt;% \n  mutate(versuchsgruppe = factor(versuchsgruppe, \n                                 labels = c(\"Proloog\", \"Quarto\", \"Katrina\")))\n\n\ngurke_ernte_tbl &lt;- gurke_len_tbl %&gt;% \n  select(versuchsgruppe, erntegewicht)\n\n\nggplot(gurke_ernte_tbl, aes(versuchsgruppe, erntegewicht)) +\n  theme_bw() +\n  geom_point()\n\n\n\n\nAbbildung 5.1— Korrelation zwischen den beiden Jahren der Messung.\n\n\n\n\n\nfit &lt;- lm(erntegewicht ~ versuchsgruppe, data = gurke_ernte_tbl)\n\nfit %&gt;% \n  anova() %&gt;% \n  parameters()\n\nParameter      | Sum_Squares | df | Mean_Square |     F |      p\n----------------------------------------------------------------\nversuchsgruppe |    5.35e+05 |  2 |    2.68e+05 | 44.36 | &lt; .001\nResiduals      |    72413.12 | 12 |     6034.43 |       |       \n\nAnova Table (Type 1 tests)\n\nfit %&gt;% \n  eta_squared()\n\n# Effect Size for ANOVA\n\nParameter      | Eta2 |       95% CI\n------------------------------------\nversuchsgruppe | 0.88 | [0.73, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\n\ngurke_ernte_tbl %$%\n  pairwise.t.test(erntegewicht, versuchsgruppe,\n                  pool.sd = TRUE, \n                  p.adjust.method = \"none\")\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  erntegewicht and versuchsgruppe \n\n        Proloog Quarto\nQuarto  8.4e-07 -     \nKatrina 5.0e-05 0.042 \n\nP value adjustment method: none \n\n\n\ngurke_ernte_tbl %$%\n  pairwise.t.test(erntegewicht, versuchsgruppe,\n                  pool.sd = TRUE, \n                  p.adjust.method = \"none\") %&gt;% \n  extract2(\"p.value\") %&gt;% \n  fullPTable() %&gt;% \n  multcompLetters()\n\nProloog  Quarto Katrina \n    \"a\"     \"b\"     \"c\" \n\n\n\nstat_tbl &lt;- gurke_ernte_tbl %&gt;% \n  group_by(versuchsgruppe) %&gt;% \n  summarise(mean = mean(erntegewicht, na.rm = TRUE),\n            sd = sd(erntegewicht, na.rm = TRUE),\n            se = sd/sqrt(n()))\n\n\nggplot(stat_tbl, aes(x = versuchsgruppe, y = mean, \n                     fill = versuchsgruppe)) + \n  theme_bw() +\n  geom_bar(stat = \"identity\") +\n  geom_errorbar(aes(ymin = mean-sd, ymax = mean+sd),\n                width = 0.2) +\n  labs(x = \"Versuchsgruppe\", y = \"Erntegewicht in [g]\") +\n  theme(legend.position = \"none\") +\n  annotate(\"text\", \n           x = 1:3, \n           y = c(635, 110, 260), \n           label = c(\"a\", \"b\", \"c\")) +\n  annotate(\"text\", x = 3, y = 700,\n           label = \"ANOVA = &lt;0.001\", size = 5) +\n  scale_fill_okabeito()\n\n\n\n\nAbbildung 5.2— Korrelation zwischen den beiden Jahren der Messung.\n\n\n\n\n\nggsave(\"img/barplot_erntegewicht.png\", \n       width = 5, height = 3)\n\n\ngurke_time_len_tbl &lt;- gurke_len_tbl %&gt;% \n  select(-pfl, -erntegewicht) %&gt;% \n  pivot_longer(cols = t1:t17,\n               values_to = \"length\",\n               names_to = \"time\") %&gt;% \n  mutate(time_fct = as_factor(time),\n         time_num = as.numeric(time_fct))\n\n\nggplot(gurke_time_len_tbl, aes(time_num, length, color = versuchsgruppe)) +\n  theme_bw() +\n  geom_point() +\n  stat_summary(fun = \"mean\", fun.min = \"min\", fun.max = \"max\", geom = \"line\") +\n  scale_color_okabeito()\n\n\n\n\nAbbildung 5.3— Korrelation zwischen den beiden Jahren der Messung.\n\n\n\n\n\nggplot(gurke_time_len_tbl, aes(time_num, length, color = versuchsgruppe)) +\n  theme_bw() +\n  geom_point() +\n  stat_summary(fun = \"mean\", fun.min = \"min\", fun.max = \"max\", geom = \"line\") +\n  facet_wrap(~ versuchsgruppe) +\n  scale_color_okabeito() \n\n\n\n\nAbbildung 5.4— Korrelation zwischen den beiden Jahren der Messung.\n\n\n\n\n\nggplot(gurke_time_len_tbl, aes(time_fct, length, color = versuchsgruppe)) +\n  theme_bw() +\n  geom_boxplot() +\n  scale_color_okabeito()\n\n\n\n\nAbbildung 5.5— Korrelation zwischen den beiden Jahren der Messung.\n\n\n\n\n\nggplot(gurke_time_len_tbl, aes(time_num, length, color = versuchsgruppe)) +\n  theme_bw() +\n  geom_jitter(position=position_dodge(0.3), shape = 4) +\n  stat_summary(fun.data=\"mean_sdl\", , fun.args = list(mult = 1), \n               geom=\"pointrange\", position=position_dodge(0.3))  +\n  stat_summary(fun = \"mean\", fun.min = \"min\", fun.max = \"max\", geom = \"line\",\n               position=position_dodge(0.3)) +\n  scale_color_okabeito()\n\n\n\n\nAbbildung 5.6— Korrelation zwischen den beiden Jahren der Messung.\n\n\n\n\n\nlm(length ~ versuchsgruppe + time + versuchsgruppe:time, gurke_time_len_tbl) %&gt;% \n  anova()\n\nAnalysis of Variance Table\n\nResponse: length\n                     Df Sum Sq Mean Sq F value  Pr(&gt;F)    \nversuchsgruppe        2 2705.7 1352.84 64.7450 &lt; 2e-16 ***\ntime                 16 3407.8  212.99 10.1933 &lt; 2e-16 ***\nversuchsgruppe:time  29  882.8   30.44  1.4569 0.06953 .  \nResiduals           219 4576.0   20.89                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\ngurke_time_len_tbl %&gt;% \n  filter(time_fct == \"t14\") %$%\n  pairwise.t.test(length, versuchsgruppe,\n                  pool.sd = FALSE, \n                  p.adjust.method = \"none\") %&gt;% \n  extract2(\"p.value\") %&gt;% \n  fullPTable() %&gt;% \n  multcompLetters()\n\nProloog  Quarto Katrina \n    \"a\"     \"b\"    \"ab\" \n\n\n\nstat_tbl &lt;- gurke_time_len_tbl %&gt;% \n  group_by(versuchsgruppe, time_fct) %&gt;% \n  summarise(mean = mean(length, na.rm = TRUE),\n            sd = sd(length, na.rm = TRUE),\n            se = sd/sqrt(n()),\n            cld_pos = mean + sd + 2)\n\n\np1 &lt;- ggplot(stat_tbl, aes(x = time_fct, y = mean, \n                     fill = versuchsgruppe)) + \n  theme_bw() +\n  geom_bar(stat = \"identity\", position = position_dodge2(preserve = \"single\")) +\n  geom_errorbar(aes(ymin = mean-sd, ymax = mean+sd),\n                width = 0.5, position = position_dodge(0.9)) +\n  labs(x = \"Zeitpunkt\", fill = \"Versuchsgruppe\", y = \"Erntegewicht in [g]\") +\n  annotate(\"text\", x = 2, y = 30,\n           label = \"ANOVA = &lt;0.001\", size = 3) +\n  theme(legend.position = \"top\") +\n  scale_fill_okabeito()\n\n\nstat_t14_tbl &lt;- stat_tbl %&gt;% \n  filter(time_fct == \"t14\")\n\n\np2 &lt;- ggplot(stat_t14_tbl, aes(x = time_fct, y = mean, \n                       fill = versuchsgruppe)) + \n  theme_bw() +\n  geom_bar(stat = \"identity\", position = position_dodge2(preserve = \"single\")) +\n  geom_errorbar(aes(ymin = mean-sd, ymax = mean+sd),\n                width = 0.5, position = position_dodge(0.9)) +\n  labs(x = \"Zeitpunkt\", fill = \"Versuchsgruppe\", y = \"Erntegewicht in [g]\") +\n  annotate(\"text\", \n           x = c(0.7, 1, 1.3), \n           y = stat_t14_tbl$cld_pos, \n           label = c(\"a\", \"b\", \"ab\")) +\n  theme(legend.position = \"none\") +\n  scale_fill_okabeito()\n\n\np1 + p2 + \n  plot_layout(widths = c(7, 1))\n\n\n\n\nAbbildung 5.7— Korrelation zwischen den beiden Jahren der Messung.\n\n\n\n\n\nggsave(\"img/time_barplot.png\", \n       width = 8, height = 5)"
  },
  {
    "objectID": "example-analysis-06.html",
    "href": "example-analysis-06.html",
    "title": "6  Laser auf Erdbeeren",
    "section": "",
    "text": "Letzte Änderung am 13. January 2024 um 17:53:03\n\n\n\n\n\n\n\nGenutzte R Pakete\n\n\n\n\npacman::p_load(tidyverse, readxl, parameters,\n               effectsize, magrittr, multcomp,\n               multcompView, rcompanion, rstatix,\n               emmeans, see, performance, fs,\n               janitor, broom,\n               conflicted)\n## resolve some conflicts with same function naming\nconflicts_prefer(dplyr::select)\nconflicts_prefer(dplyr::filter)\nconflicts_prefer(effectsize::eta_squared)\nconflicts_prefer(magrittr::set_names)\n\n\n\n\n\n\nAbbildung 6.1— Vogelperspektive für unseren Versuch mit Pilzbefall. Leider finden wir nur den Block I und II auf dem Grün 1 sowie die Blöcke III und IV auf dem Grün 2.\n\n\n\nberry_files &lt;- list.files(\"data/strawberry\",\n                          pattern = \"^E\", full.names = TRUE)\n\n\nberry_lst &lt;- map(berry_files, read_table, \n                 skip = 2, col_names = FALSE, col_types = cols())\n\n\nberry_lst &lt;- map(berry_files, function(x){\n  tmp_tbl &lt;- read_table(x, \n                        skip = 2, col_names = FALSE, col_types = cols()) \n  file_name &lt;- basename(x) %&gt;% \n    path_ext_remove() %&gt;% \n    str_replace_all(\"\\\\s\", \"_\")\n  tmp_tbl &lt;- tmp_tbl %&gt;% \n    set_names(c(\"wave\", file_name)) \n  return(tmp_tbl)\n})\n\n\nberry_tbl &lt;- berry_lst %&gt;% \n  reduce(left_join, by = \"wave\") %&gt;% \n  pivot_longer(cols = E_1.1._w1:last_col(),\n               names_sep = \"\\\\._\",\n               values_to = \"values\",\n               names_to = c(\"E\", \"rep\")) %&gt;% \n  group_by(wave, E) %&gt;% \n  summarise(mean = mean(values))\n\n\nggplot(berry_tbl, aes(wave, mean, color = E)) +\n  theme_bw() +\n  geom_line() +\n  theme(legend.position = \"none\") \n\n\n\n\nAbbildung 6.2— Korrelation zwischen den beiden Jahren der Messung.\n\n\n\n\n\nsugar_tbl &lt;- read_excel(\"data/strawberry_sugar.xlsx\") %&gt;% \n  clean_names() %&gt;% \n  select(-brixwert, -brix_mittel_note, -messwiederholung,\n         -g_zucker_l_saft_mittel_note, -oe_einzelfrucht) %&gt;% \n  filter(!is.na(brix_einzelfrucht)) %&gt;% \n  mutate(E = str_c(\"E_\", boniturnote, \".\", fruchtnummer))\n\n\nberry_sugar_tbl &lt;- left_join(berry_tbl, sugar_tbl,\n                             by = c(\"E\" = \"E\")) %&gt;% \n  filter(boniturnote %in% c(1, 2, 3, 4, 5)) %&gt;% \n  mutate(boniturnote = as_factor(boniturnote))\n\n\nwave_vec &lt;- berry_sugar_tbl %&gt;% pull(wave) %&gt;% unique()\n\nWir haben insgesamt 1740 Wellenlängen.\n\nwave_vec &lt;- wave_vec[1:20]\n\n\nberry_sugar_tbl %&gt;% \n  filter(wave == 231) %&gt;% \n  ggplot(aes(x = brix_einzelfrucht, y = mean,\n             color = boniturnote)) +\n  theme_bw() +\n  geom_point() +\n  stat_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~ wave) +\n  scale_color_okabeito() \n\n\n\n\nAbbildung 6.3— Korrelation zwischen den beiden Jahren der Messung.\n\n\n\n\n\nberry_sugar_tbl %&gt;% \n  filter(wave == 231) %$% \n  lm(mean ~ brix_einzelfrucht) %&gt;% \n  glance() %&gt;% \n  pull(r.squared)\n\n[1] 0.01267805\n\n\n\nrsquare_vec &lt;- map_dbl(wave_vec, function(x){\n  rsquare &lt;- berry_sugar_tbl %&gt;% \n    filter(wave == x) %$% \n    lm(brix_einzelfrucht ~ mean + boniturnote) %&gt;%\n    glance() %&gt;% \n    pull(adj.r.squared)\n  return(rsquare)\n}, .progress = TRUE) %&gt;% \n  set_names(wave_vec)\n\n\nwhich.max(rsquare_vec)\n\n238 \n 15 \n\nrsquare_vec[15]\n\n      238 \n0.6111646 \n\n\n\nberry_sugar_tbl %&gt;% \n  filter(wave == wave_vec[15]) %&gt;% \n  ggplot(aes(x = mean, y = brix_einzelfrucht,\n             color = boniturnote)) +\n  theme_bw() +\n  geom_text(aes(label = E)) +\n  stat_smooth(method = \"lm\", se = FALSE) +\n  facet_wrap(~ wave) +\n  scale_color_okabeito() \n\n\n\n\nAbbildung 6.4— Korrelation zwischen den beiden Jahren der Messung."
  },
  {
    "objectID": "example-analysis-07.html#daten-einlesen",
    "href": "example-analysis-07.html#daten-einlesen",
    "title": "7  Eisen und Zink in Salat",
    "section": "7.1 Daten einlesen",
    "text": "7.1 Daten einlesen\n\ndata_tbl &lt;- read_csv2(\"data/fe_zn_salad.csv\") %&gt;% \n  clean_names() %&gt;% \n  fill(eisendungeform) %&gt;% \n  mutate(eisendungeform = str_replace_all(eisendungeform, \"\\u0096 7 \", \"\"),\n         versuchsgruppe = str_c(eisendungeform, \"_\", eisendungung)) %&gt;% \n  pivot_longer(cols = zn_blanchiert:fe_ungewaschen,\n               names_to = \"outcome\",\n               values_to = \"rsp\")"
  },
  {
    "objectID": "example-analysis-07.html#daten-auswerten",
    "href": "example-analysis-07.html#daten-auswerten",
    "title": "7  Eisen und Zink in Salat",
    "section": "7.2 Daten auswerten",
    "text": "7.2 Daten auswerten\n\nnested_tbl &lt;- data_tbl %&gt;% \n  select(versuchsgruppe, outcome, rsp) %&gt;% \n  group_by(outcome) %&gt;% \n  nest() \n\naov_res &lt;- nested_tbl %&gt;% \n  mutate(model = map(data, ~lm(rsp ~ versuchsgruppe, data = .x))) %&gt;% \n  mutate(anova = map(model, anova)) %&gt;% \n  mutate(parameter = map(anova, model_parameters)) %&gt;% \n  select(outcome, parameter) %&gt;% \n  unnest(parameter) %&gt;% \n  clean_names() %&gt;% \n  mutate(p = pvalue(p)) %&gt;% \n  filter(parameter != \"Residuals\") %&gt;% \n  select(outcome, parameter, p)\n\naov_res %&gt;% \n  kable(align = \"c\", \"pipe\")\n\n\n\n\noutcome\nparameter\np\n\n\n\n\nzn_blanchiert\nversuchsgruppe\n0.538\n\n\nzn_ungewaschen\nversuchsgruppe\n0.634\n\n\nfe_blanchiert\nversuchsgruppe\n&lt;0.001\n\n\nfe_ungewaschen\nversuchsgruppe\n&lt;0.001\n\n\n\n\nemm_tbl &lt;- nested_tbl %&gt;% \n  mutate(model = map(data, ~lm(rsp ~ versuchsgruppe, data = .x))) %&gt;% \n  mutate(emm = map(model, emmeans, ~versuchsgruppe)) %&gt;% \n  mutate(contrast = map(emm, contrast, method = \"pairwise\", \n                        adjust = \"none\")) %&gt;% \n  mutate(cld = map(emm, cld, Letters = letters, adjust = \"none\"))\n  \nemm_tbl %&gt;% \n  mutate(contrast = map(contrast, as_tibble)) %&gt;% \n  unnest(contrast) %&gt;% \n  select(outcome, contrast, p.value) %&gt;% \n  mutate(p.value = pvalue(p.value)) %&gt;% \n  print(n = 10)\n\n# A tibble: 144 × 3\n# Groups:   outcome [4]\n   outcome       contrast                        p.value\n   &lt;chr&gt;         &lt;chr&gt;                           &lt;chr&gt;  \n 1 zn_blanchiert (Fe-EDDHA_0.2) - (Fe-EDDHA_0.3) 0.836  \n 2 zn_blanchiert (Fe-EDDHA_0.2) - (Fe-EDDHA_0.4) 0.118  \n 3 zn_blanchiert (Fe-EDDHA_0.2) - (Fe-EDDHA_0.6) 0.357  \n 4 zn_blanchiert (Fe-EDDHA_0.2) - FeSO4 H2O_0.2  0.682  \n 5 zn_blanchiert (Fe-EDDHA_0.2) - FeSO4 H2O_0.3  0.573  \n 6 zn_blanchiert (Fe-EDDHA_0.2) - FeSO4 H2O_0.4  0.878  \n 7 zn_blanchiert (Fe-EDDHA_0.2) - FeSO4 H2O_0.6  0.492  \n 8 zn_blanchiert (Fe-EDDHA_0.2) - Kontrolle_0    0.168  \n 9 zn_blanchiert (Fe-EDDHA_0.3) - (Fe-EDDHA_0.4) 0.171  \n10 zn_blanchiert (Fe-EDDHA_0.3) - (Fe-EDDHA_0.6) 0.474  \n# ℹ 134 more rows\n\nemm_tbl %&gt;% \n  mutate(cld = map(cld, arrange, versuchsgruppe)) %&gt;% \n  unnest(cld) %&gt;% \n  select(outcome, versuchsgruppe, .group) %&gt;% \n  print(n = Inf)\n\n# A tibble: 36 × 3\n# Groups:   outcome [4]\n   outcome        versuchsgruppe .group  \n   &lt;chr&gt;          &lt;fct&gt;          &lt;chr&gt;   \n 1 zn_blanchiert  Fe-EDDHA_0.2   \" a\"    \n 2 zn_blanchiert  Fe-EDDHA_0.3   \" a\"    \n 3 zn_blanchiert  Fe-EDDHA_0.4   \" a\"    \n 4 zn_blanchiert  Fe-EDDHA_0.6   \" a\"    \n 5 zn_blanchiert  FeSO4 H2O_0.2  \" a\"    \n 6 zn_blanchiert  FeSO4 H2O_0.3  \" a\"    \n 7 zn_blanchiert  FeSO4 H2O_0.4  \" a\"    \n 8 zn_blanchiert  FeSO4 H2O_0.6  \" a\"    \n 9 zn_blanchiert  Kontrolle_0    \" a\"    \n10 zn_ungewaschen Fe-EDDHA_0.2   \" a\"    \n11 zn_ungewaschen Fe-EDDHA_0.3   \" a\"    \n12 zn_ungewaschen Fe-EDDHA_0.4   \" a\"    \n13 zn_ungewaschen Fe-EDDHA_0.6   \" a\"    \n14 zn_ungewaschen FeSO4 H2O_0.2  \" a\"    \n15 zn_ungewaschen FeSO4 H2O_0.3  \" a\"    \n16 zn_ungewaschen FeSO4 H2O_0.4  \" a\"    \n17 zn_ungewaschen FeSO4 H2O_0.6  \" a\"    \n18 zn_ungewaschen Kontrolle_0    \" a\"    \n19 fe_blanchiert  Fe-EDDHA_0.2   \"  bc  \"\n20 fe_blanchiert  Fe-EDDHA_0.3   \"  bc  \"\n21 fe_blanchiert  Fe-EDDHA_0.4   \"   cd \"\n22 fe_blanchiert  Fe-EDDHA_0.6   \"    d \"\n23 fe_blanchiert  FeSO4 H2O_0.2  \" ab   \"\n24 fe_blanchiert  FeSO4 H2O_0.3  \"    d \"\n25 fe_blanchiert  FeSO4 H2O_0.4  \"    d \"\n26 fe_blanchiert  FeSO4 H2O_0.6  \"     e\"\n27 fe_blanchiert  Kontrolle_0    \" a    \"\n28 fe_ungewaschen Fe-EDDHA_0.2   \"  b   \"\n29 fe_ungewaschen Fe-EDDHA_0.3   \"  bc  \"\n30 fe_ungewaschen Fe-EDDHA_0.4   \"   cd \"\n31 fe_ungewaschen Fe-EDDHA_0.6   \"    d \"\n32 fe_ungewaschen FeSO4 H2O_0.2  \"  b   \"\n33 fe_ungewaschen FeSO4 H2O_0.3  \"  bc  \"\n34 fe_ungewaschen FeSO4 H2O_0.4  \"  bc  \"\n35 fe_ungewaschen FeSO4 H2O_0.6  \"     e\"\n36 fe_ungewaschen Kontrolle_0    \" a    \"\n\ngg_func &lt;- function(data){\n  data %&gt;% \n    mutate(.group = str_replace_all(.group, \"\\\\s\", \"\")) %&gt;% \n    ggplot(aes(versuchsgruppe, emmean)) +\n    theme_minimal() +\n    geom_bar(stat = \"identity\")  +\n    geom_errorbar(aes(ymin = emmean - SE, ymax = emmean + SE), width = 0.2) +\n    geom_text(aes(label = .group, y = (emmean + SE) + (0.05 * (emmean + SE)))) +\n    theme(axis.text.x = element_text(angle = -45, hjust = 0))\n}\n\nPlot math expression\n\nemm_tbl %&gt;% \n  mutate(gg = map(cld, gg_func)) %&gt;% \n  pluck(\"gg\", 1) +\n  labs(x = expression(Eisendüngeform~und~-höhe~\"[kg ha]\"^-1),\n       y = expression(Zn-Gehalt~\"[\"~mg%.%(100~g~FM)^-1~\"]\"))\n\nemm_tbl %&gt;% \n  mutate(gg = map(cld, gg_func)) %&gt;% \n  pluck(\"gg\", 2) +\n  labs(x = expression(Eisendüngeform~und~-höhe~\"[kg ha]\"^-1),\n       y = expression(Zn-Gehalt~\"[\"~mg%.%(kg~TM)^-1~\"]\"))\n\nemm_tbl %&gt;% \n  mutate(gg = map(cld, gg_func)) %&gt;% \n  pluck(\"gg\", 3) +\n  labs(x = expression(Eisendüngeform~und~-höhe~\"[kg ha]\"^-1),\n       y = expression(Fe-Gehalt~\"[\"~mg%.%(100~g~FM)^-1~\"]\"))\n\nemm_tbl %&gt;% \n  mutate(gg = map(cld, gg_func)) %&gt;% \n  pluck(\"gg\", 4) +\n  labs(x = expression(Eisendüngeform~und~-höhe~\"[kg ha]\"^-1),\n       y = expression(Fe-Gehalt~\"[\"~mg%.%(kg~TM)^-1~\"]\"))\n\n\n\n\n\n\n\n(a) zn_blanchiert\n\n\n\n\n\n\n\n(b) zn_ungewaschen\n\n\n\n\n\n\n\n\n\n(c) fe_blanchiert\n\n\n\n\n\n\n\n(d) fe_ungewaschen\n\n\n\n\nAbbildung 7.1— Barplots der Mittelwerte und Standardfehler für die vier Outcomes."
  }
]